{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pyaudio\n",
    "# import time\n",
    "# import librosa\n",
    "\n",
    "# class AudioHandler(object):\n",
    "#     def __init__(self):\n",
    "#         self.FORMAT = pyaudio.paFloat32\n",
    "#         self.CHANNELS = 1\n",
    "#         self.RATE = 44100\n",
    "#         self.CHUNK = 1024 * 2\n",
    "#         self.p = None\n",
    "#         self.stream = None\n",
    "\n",
    "#     def start(self):\n",
    "#         self.p = pyaudio.PyAudio()\n",
    "#         self.stream = self.p.open(format=self.FORMAT,\n",
    "#                                   channels=self.CHANNELS,\n",
    "#                                   rate=self.RATE,\n",
    "#                                   input=True,\n",
    "#                                   output=False,\n",
    "#                                   stream_callback=self.callback,\n",
    "#                                   frames_per_buffer=self.CHUNK)\n",
    "\n",
    "#     def stop(self):\n",
    "#         self.stream.close()\n",
    "#         self.p.terminate()\n",
    "\n",
    "#     def callback(self, in_data, frame_count, time_info, flag):\n",
    "#         numpy_array = np.frombuffer(in_data, dtype=np.float32)\n",
    "#         librosa.feature.mfcc(numpy_array)\n",
    "#         return None, pyaudio.paContinue\n",
    "\n",
    "#     def mainloop(self):\n",
    "#         while (self.stream.is_active()): # if using button you can set self.stream to 0 (self.stream = 0), otherwise you can use a stop condition\n",
    "#             time.sleep(2.0)\n",
    "\n",
    "\n",
    "# audio = AudioHandler()\n",
    "# audio.start()     # open the the stream\n",
    "# audio.mainloop()  # main operations with librosa\n",
    "# audio.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From tutorial:\n",
    "\n",
    "'''\n",
    "https://www.youtube.com/watch?v=AShHJdSIxkY\n",
    "'''\n",
    "\n",
    "import pyaudio \n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib tk\n",
    "\n",
    "import pyaudio\n",
    "p = pyaudio.PyAudio()\n",
    "info = p.get_host_api_info_by_index(0)\n",
    "numdevices = info.get('deviceCount')\n",
    "for i in range(0, numdevices):\n",
    "        if (p.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "            print(\"Input Device id \", i, \" - \", p.get_device_info_by_host_api_device_index(0, i).get('name'))\n",
    "\n",
    "CHUNK = 1024 * 4\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=True,\n",
    "    output=True,\n",
    "    frames_per_buffer=CHUNK\n",
    ")\n",
    "\n",
    "\n",
    "data = stream.read(CHUNK)\n",
    "data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_model = tf.keras.models.load_model('../data/saved_models/mel_1_sec_model_(95acc)/mel_1_sec_model')\n",
    "\n",
    "# Check its architecture\n",
    "mel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stft_snapshots(index, stft_dict):\n",
    "    \n",
    "    r_id = index['recording_id']\n",
    "\n",
    "    f_path = get_filepath(r_id)\n",
    "    \n",
    "    audio = tfio.audio.AudioIOTensor(f_path)\n",
    "    sr = audio.rate\n",
    "\n",
    "#     dur = get_duration(index)\n",
    "    dur = 1\n",
    "    \n",
    "    for i in range(dur):\n",
    "        \n",
    "        start = i + 1 * sr * floor(index['t_min'])\n",
    "        stop = start + sr\n",
    "\n",
    "        audio_slice = audio[start: stop + 1]\n",
    "        \n",
    "        audio_tensor = tf.squeeze(audio_slice, axis=[-1])\n",
    "        \n",
    "        tensor = tf.cast(audio_tensor, tf.float32)\n",
    "        \n",
    "        spectrogram = tfio.experimental.audio.spectrogram(\n",
    "            tensor,\n",
    "            nfft=512,\n",
    "            window=512,\n",
    "            stride=256\n",
    "        )\n",
    "        \n",
    "        mel_spectrogram = tfio.experimental.audio.melscale(\n",
    "            spectrogram, \n",
    "            rate=sr, \n",
    "            mels=128, \n",
    "            fmin=93.75,     # 20, \n",
    "            fmax=11627.90) # 15000)\n",
    "            \n",
    "        dbscale_mel_spectrogram = tfio.experimental.audio.dbscale(\n",
    "            mel_spectrogram, \n",
    "            top_db=80)\n",
    "        \n",
    "        \n",
    "        stft_dict['dbscale_mel'].append(mel_spectrogram.numpy())\n",
    "        stft_dict['mel'].append(mel_spectrogram.numpy())\n",
    "        stft_dict['stft'].append(spectrogram.numpy())\n",
    "        stft_dict['species_id'].append(index['species_id'])\n",
    "    \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_audio(audio_input):\n",
    "    \n",
    "    audio = tfio.auido.AudioIOTensor(audio_input)\n",
    "    sr = audio.rate\n",
    "    \n",
    "    audio_tensor = tf.squeeze(audio, axis=[-1])\n",
    "    \n",
    "    tensor = tf.cast(audio_tensor, tf.float32)\n",
    "    \n",
    "    spectrogram = tfio.experimental.audio.spectrogram(\n",
    "        tensor,\n",
    "        nfft=512,\n",
    "        window=512,\n",
    "        stride=256)\n",
    "\n",
    "    mel_spectrogram = tfio.experimental.audio.melscale(\n",
    "        spectrogram, \n",
    "        rate=sr, \n",
    "        mels=128, \n",
    "        fmin=93.75,     # 20, \n",
    "        fmax=11627.90) # 15000)\n",
    "\n",
    "    dbscale_mel_spectrogram = tfio.experimental.audio.dbscale(\n",
    "        mel_spectrogram, \n",
    "        top_db=80)\n",
    "    \n",
    "    \n",
    "    return dbscale_mel_spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources:\n",
    "\n",
    "PyAudio\n",
    "-[Insatlling PyAudio on Python 3.7](https://stackoverflow.com/questions/54998028/how-do-i-install-pyaudio-on-python-3-7)\n",
    "- [Select Specific Input Device with PyAudio](https://stackoverflow.com/questions/36894315/how-to-select-a-specific-input-device-with-pyaudio)  \n",
    "\n",
    "\n",
    "- [Let's Build an Audio Spectrum Analyzer in Python (pt1)](https://www.youtube.com/watch?v=AShHJdSIxkY)  \n",
    "\n",
    "Librosa\n",
    "- [Librosa with Microphone Input](https://stackoverflow.com/questions/59056786/python-librosa-with-microphone-input)  \n",
    "- [Librosa Documentation](https://librosa.org/doc/latest/core.html#signal-generation)\n",
    "\n",
    "\n",
    "Tensorflow\n",
    "- [Tensorflow Audio Data Prep and Augmentation](https://www.tensorflow.org/io/tutorials/audio#read_an_audio_file)  \n",
    "- [Save and load models](https://www.tensorflow.org/tutorials/keras/save_and_load) \n",
    "- \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- [Paper: Speech Recognition](https://arxiv.org/pdf/1904.08779.pdf)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sounddevice as sd\n",
    "# print sd.query_devices() \n",
    "\n",
    "\n",
    "pyaudio.Stream(PA_manager, \n",
    "               rate, \n",
    "               channels, \n",
    "               format, \n",
    "               input=False, \n",
    "               output=False, \n",
    "               input_device_index=None, \n",
    "               output_device_index=None, \n",
    "               frames_per_buffer=1024, \n",
    "               start=True, \n",
    "               input_host_api_specific_stream_info=None, \n",
    "               output_host_api_specific_stream_info=None, \n",
    "               stream_callback=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "chunk = 1024  # Record in chunks of 1024 samples\n",
    "sample_format = pyaudio.paInt16  # 16 bits per sample\n",
    "channels = 1\n",
    "fs = 44100  # Record at 44100 samples per second\n",
    "seconds = 3\n",
    "filename = \"output.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
    "\n",
    "print('Recording')\n",
    "\n",
    "stream = p.open(format=sample_format,\n",
    "                channels=channels,\n",
    "                rate=fs,\n",
    "                frames_per_buffer=chunk,\n",
    "                input=True)\n",
    "\n",
    "frames = []  # Initialize array to store frames\n",
    "\n",
    "# Store data in chunks for 3 seconds\n",
    "for i in range(0, int(fs / chunk * seconds)):\n",
    "    print('stream')\n",
    "    data = stream.read(chunk)\n",
    "    frames.append(data)\n",
    "\n",
    "# Stop and close the stream \n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "# Terminate the PortAudio interface\n",
    "p.terminate()\n",
    "\n",
    "print('Finished recording')\n",
    "\n",
    "# Save the recorded data as a WAV file\n",
    "wf = wave.open(filename, 'wb')\n",
    "wf.setnchannels(channels)\n",
    "wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "wf.setframerate(fs)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
